<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_oj6uyb282fur-1>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-1,lower-latin) ". "}.lst-kix_oj6uyb282fur-0>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-0,decimal) ". "}.lst-kix_oj6uyb282fur-2>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-2,lower-roman) ". "}ol.lst-kix_oj6uyb282fur-3.start{counter-reset:lst-ctn-kix_oj6uyb282fur-3 0}ul.lst-kix_rq3xt9bxxo4d-8{list-style-type:none}ul.lst-kix_rq3xt9bxxo4d-7{list-style-type:none}ul.lst-kix_rq3xt9bxxo4d-6{list-style-type:none}ul.lst-kix_rq3xt9bxxo4d-5{list-style-type:none}ul.lst-kix_rq3xt9bxxo4d-4{list-style-type:none}ul.lst-kix_rq3xt9bxxo4d-3{list-style-type:none}ul.lst-kix_rq3xt9bxxo4d-2{list-style-type:none}ul.lst-kix_rq3xt9bxxo4d-1{list-style-type:none}.lst-kix_oj6uyb282fur-6>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-6,decimal) ". "}ul.lst-kix_rq3xt9bxxo4d-0{list-style-type:none}.lst-kix_oj6uyb282fur-7>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-7,lower-latin) ". "}ol.lst-kix_kqerte93uwcj-4.start{counter-reset:lst-ctn-kix_kqerte93uwcj-4 0}.lst-kix_9g9y5bz36tci-7>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-7}ol.lst-kix_9g9y5bz36tci-6.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-6 0}.lst-kix_oj6uyb282fur-5>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-5,lower-roman) ". "}.lst-kix_oj6uyb282fur-4>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-4,lower-latin) ". "}.lst-kix_oj6uyb282fur-3>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-3,decimal) ". "}ul.lst-kix_5fifcvmgojtk-1{list-style-type:none}ul.lst-kix_5fifcvmgojtk-0{list-style-type:none}ul.lst-kix_5fifcvmgojtk-3{list-style-type:none}ul.lst-kix_5fifcvmgojtk-2{list-style-type:none}.lst-kix_p2qk8baner5z-8>li:before{content:"\0025a0   "}.lst-kix_p2qk8baner5z-6>li:before{content:"\0025cf   "}ul.lst-kix_3bkhzfle7x0q-4{list-style-type:none}ul.lst-kix_3bkhzfle7x0q-5{list-style-type:none}ul.lst-kix_5fifcvmgojtk-8{list-style-type:none}.lst-kix_p2qk8baner5z-5>li:before{content:"\0025a0   "}.lst-kix_p2qk8baner5z-7>li:before{content:"\0025cb   "}ul.lst-kix_3bkhzfle7x0q-2{list-style-type:none}ul.lst-kix_3bkhzfle7x0q-3{list-style-type:none}ul.lst-kix_3bkhzfle7x0q-0{list-style-type:none}ul.lst-kix_5fifcvmgojtk-5{list-style-type:none}ul.lst-kix_3bkhzfle7x0q-1{list-style-type:none}ul.lst-kix_5fifcvmgojtk-4{list-style-type:none}ul.lst-kix_5fifcvmgojtk-7{list-style-type:none}ul.lst-kix_5fifcvmgojtk-6{list-style-type:none}.lst-kix_kqerte93uwcj-7>li{counter-increment:lst-ctn-kix_kqerte93uwcj-7}.lst-kix_p2qk8baner5z-3>li:before{content:"\0025cf   "}.lst-kix_oj6uyb282fur-8>li{counter-increment:lst-ctn-kix_oj6uyb282fur-8}.lst-kix_p2qk8baner5z-4>li:before{content:"\0025cb   "}ul.lst-kix_3bkhzfle7x0q-8{list-style-type:none}.lst-kix_psld3evi66f5-1>li{counter-increment:lst-ctn-kix_psld3evi66f5-1}.lst-kix_5fifcvmgojtk-3>li:before{content:"\0025cf   "}.lst-kix_9g9y5bz36tci-5>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-5}ul.lst-kix_3bkhzfle7x0q-6{list-style-type:none}ul.lst-kix_3bkhzfle7x0q-7{list-style-type:none}ul.lst-kix_43m80evrq7j3-8{list-style-type:none}ul.lst-kix_43m80evrq7j3-7{list-style-type:none}.lst-kix_43m80evrq7j3-8>li:before{content:"\0025a0   "}.lst-kix_5fifcvmgojtk-2>li:before{content:"\0025a0   "}.lst-kix_9g9y5bz36tci-0>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-0,decimal) ". "}.lst-kix_5fifcvmgojtk-1>li:before{content:"\0025cb   "}.lst-kix_9g9y5bz36tci-3>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-3}ol.lst-kix_9g9y5bz36tci-7.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-7 0}.lst-kix_5fifcvmgojtk-0>li:before{content:"\0025cf   "}.lst-kix_9g9y5bz36tci-3>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-3,decimal) ". "}.lst-kix_9g9y5bz36tci-5>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-5,lower-roman) ". "}.lst-kix_9g9y5bz36tci-4>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-4,lower-latin) ". "}.lst-kix_oj6uyb282fur-6>li{counter-increment:lst-ctn-kix_oj6uyb282fur-6}ul.lst-kix_43m80evrq7j3-2{list-style-type:none}ul.lst-kix_43m80evrq7j3-1{list-style-type:none}ol.lst-kix_9g9y5bz36tci-1.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-1 0}ul.lst-kix_43m80evrq7j3-0{list-style-type:none}.lst-kix_9g9y5bz36tci-1>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-1,lower-latin) ". "}.lst-kix_kqerte93uwcj-2>li{counter-increment:lst-ctn-kix_kqerte93uwcj-2}ul.lst-kix_43m80evrq7j3-6{list-style-type:none}ul.lst-kix_43m80evrq7j3-5{list-style-type:none}ul.lst-kix_43m80evrq7j3-4{list-style-type:none}ul.lst-kix_43m80evrq7j3-3{list-style-type:none}.lst-kix_9g9y5bz36tci-2>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-2,lower-roman) ". "}.lst-kix_kqerte93uwcj-5>li{counter-increment:lst-ctn-kix_kqerte93uwcj-5}.lst-kix_6rknmht6yj93-8>li:before{content:"\0025a0   "}.lst-kix_psld3evi66f5-8>li{counter-increment:lst-ctn-kix_psld3evi66f5-8}.lst-kix_6rknmht6yj93-6>li:before{content:"\0025cf   "}.lst-kix_6rknmht6yj93-7>li:before{content:"\0025cb   "}.lst-kix_9g9y5bz36tci-7>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-7,lower-latin) ". "}.lst-kix_psld3evi66f5-5>li{counter-increment:lst-ctn-kix_psld3evi66f5-5}.lst-kix_6rknmht6yj93-5>li:before{content:"\0025a0   "}.lst-kix_9g9y5bz36tci-6>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-6,decimal) ". "}.lst-kix_6rknmht6yj93-2>li:before{content:"\0025a0   "}.lst-kix_6rknmht6yj93-3>li:before{content:"\0025cf   "}.lst-kix_oj6uyb282fur-8>li:before{content:"" counter(lst-ctn-kix_oj6uyb282fur-8,lower-roman) ". "}.lst-kix_6rknmht6yj93-0>li:before{content:"\0025cf   "}.lst-kix_6rknmht6yj93-4>li:before{content:"\0025cb   "}.lst-kix_9g9y5bz36tci-8>li:before{content:"" counter(lst-ctn-kix_9g9y5bz36tci-8,lower-roman) ". "}ol.lst-kix_kqerte93uwcj-8{list-style-type:none}ol.lst-kix_kqerte93uwcj-7{list-style-type:none}ol.lst-kix_kqerte93uwcj-6{list-style-type:none}ol.lst-kix_kqerte93uwcj-5{list-style-type:none}ol.lst-kix_kqerte93uwcj-4{list-style-type:none}ol.lst-kix_9g9y5bz36tci-0.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-0 0}ol.lst-kix_kqerte93uwcj-3{list-style-type:none}.lst-kix_6rknmht6yj93-1>li:before{content:"\0025cb   "}ol.lst-kix_kqerte93uwcj-2{list-style-type:none}ol.lst-kix_kqerte93uwcj-1{list-style-type:none}ol.lst-kix_kqerte93uwcj-0{list-style-type:none}ol.lst-kix_psld3evi66f5-3.start{counter-reset:lst-ctn-kix_psld3evi66f5-3 0}.lst-kix_3bkhzfle7x0q-1>li:before{content:"\0025cb   "}.lst-kix_3bkhzfle7x0q-5>li:before{content:"\0025a0   "}.lst-kix_trboa99q619-7>li:before{content:"\0025cb   "}.lst-kix_3bkhzfle7x0q-3>li:before{content:"\0025cf   "}.lst-kix_3bkhzfle7x0q-7>li:before{content:"\0025cb   "}.lst-kix_psld3evi66f5-6>li{counter-increment:lst-ctn-kix_psld3evi66f5-6}.lst-kix_oj6uyb282fur-3>li{counter-increment:lst-ctn-kix_oj6uyb282fur-3}ol.lst-kix_oj6uyb282fur-4.start{counter-reset:lst-ctn-kix_oj6uyb282fur-4 0}ol.lst-kix_9g9y5bz36tci-8.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-8 0}ol.lst-kix_kqerte93uwcj-0.start{counter-reset:lst-ctn-kix_kqerte93uwcj-0 0}ol.lst-kix_psld3evi66f5-6.start{counter-reset:lst-ctn-kix_psld3evi66f5-6 0}.lst-kix_psld3evi66f5-7>li{counter-increment:lst-ctn-kix_psld3evi66f5-7}.lst-kix_c0hzicc8kgm0-1>li:before{content:"\0025cb   "}ol.lst-kix_oj6uyb282fur-1.start{counter-reset:lst-ctn-kix_oj6uyb282fur-1 0}.lst-kix_oj6uyb282fur-5>li{counter-increment:lst-ctn-kix_oj6uyb282fur-5}.lst-kix_43m80evrq7j3-7>li:before{content:"\0025cb   "}ul.lst-kix_trboa99q619-6{list-style-type:none}.lst-kix_pjq3nr88nkxs-3>li:before{content:"\0025cf   "}ul.lst-kix_trboa99q619-7{list-style-type:none}.lst-kix_5fifcvmgojtk-4>li:before{content:"\0025cb   "}ul.lst-kix_trboa99q619-8{list-style-type:none}ol.lst-kix_psld3evi66f5-8{list-style-type:none}.lst-kix_5fifcvmgojtk-6>li:before{content:"\0025cf   "}.lst-kix_43m80evrq7j3-5>li:before{content:"\0025a0   "}ol.lst-kix_psld3evi66f5-5.start{counter-reset:lst-ctn-kix_psld3evi66f5-5 0}.lst-kix_5fifcvmgojtk-8>li:before{content:"\0025a0   "}.lst-kix_p2qk8baner5z-1>li:before{content:"\0025cb   "}.lst-kix_43m80evrq7j3-3>li:before{content:"\0025cf   "}.lst-kix_pjq3nr88nkxs-1>li:before{content:"\0025cb   "}.lst-kix_43m80evrq7j3-1>li:before{content:"\0025cb   "}.lst-kix_9g9y5bz36tci-4>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-4}.lst-kix_c0hzicc8kgm0-3>li:before{content:"\0025cf   "}.lst-kix_kqerte93uwcj-6>li{counter-increment:lst-ctn-kix_kqerte93uwcj-6}.lst-kix_8giikabfykif-1>li:before{content:"\0025cb   "}.lst-kix_psld3evi66f5-0>li:before{content:"" counter(lst-ctn-kix_psld3evi66f5-0,upper-roman) ". "}.lst-kix_pjq3nr88nkxs-7>li:before{content:"\0025cb   "}ol.lst-kix_psld3evi66f5-2{list-style-type:none}ol.lst-kix_psld3evi66f5-3{list-style-type:none}ul.lst-kix_trboa99q619-0{list-style-type:none}ol.lst-kix_psld3evi66f5-0{list-style-type:none}.lst-kix_c0hzicc8kgm0-5>li:before{content:"\0025a0   "}.lst-kix_c0hzicc8kgm0-7>li:before{content:"\0025cb   "}ul.lst-kix_trboa99q619-1{list-style-type:none}ol.lst-kix_psld3evi66f5-1{list-style-type:none}ul.lst-kix_trboa99q619-2{list-style-type:none}ol.lst-kix_psld3evi66f5-6{list-style-type:none}ul.lst-kix_trboa99q619-3{list-style-type:none}ol.lst-kix_psld3evi66f5-7{list-style-type:none}ul.lst-kix_trboa99q619-4{list-style-type:none}ol.lst-kix_psld3evi66f5-4{list-style-type:none}ul.lst-kix_trboa99q619-5{list-style-type:none}.lst-kix_pjq3nr88nkxs-5>li:before{content:"\0025a0   "}ol.lst-kix_psld3evi66f5-5{list-style-type:none}.lst-kix_trboa99q619-1>li:before{content:"\0025cb   "}.lst-kix_kqerte93uwcj-7>li:before{content:"" counter(lst-ctn-kix_kqerte93uwcj-7,lower-latin) ". "}ol.lst-kix_psld3evi66f5-4.start{counter-reset:lst-ctn-kix_psld3evi66f5-4 0}.lst-kix_8giikabfykif-7>li:before{content:"\0025cb   "}.lst-kix_trboa99q619-3>li:before{content:"\0025cf   "}.lst-kix_kqerte93uwcj-5>li:before{content:"(" counter(lst-ctn-kix_kqerte93uwcj-5,lower-roman) ") "}.lst-kix_kqerte93uwcj-3>li:before{content:"(" counter(lst-ctn-kix_kqerte93uwcj-3,decimal) ") "}.lst-kix_trboa99q619-5>li:before{content:"\0025a0   "}ol.lst-kix_oj6uyb282fur-2.start{counter-reset:lst-ctn-kix_oj6uyb282fur-2 0}.lst-kix_8giikabfykif-3>li:before{content:"\0025cf   "}.lst-kix_8giikabfykif-5>li:before{content:"\0025a0   "}.lst-kix_oj6uyb282fur-4>li{counter-increment:lst-ctn-kix_oj6uyb282fur-4}ul.lst-kix_p2qk8baner5z-8{list-style-type:none}.lst-kix_kqerte93uwcj-0>li{counter-increment:lst-ctn-kix_kqerte93uwcj-0}ul.lst-kix_p2qk8baner5z-5{list-style-type:none}.lst-kix_kqerte93uwcj-1>li:before{content:"" counter(lst-ctn-kix_kqerte93uwcj-1,lower-latin) ") "}ul.lst-kix_p2qk8baner5z-4{list-style-type:none}ul.lst-kix_p2qk8baner5z-7{list-style-type:none}ul.lst-kix_p2qk8baner5z-6{list-style-type:none}ul.lst-kix_p2qk8baner5z-1{list-style-type:none}ul.lst-kix_p2qk8baner5z-0{list-style-type:none}ul.lst-kix_p2qk8baner5z-3{list-style-type:none}ul.lst-kix_p2qk8baner5z-2{list-style-type:none}.lst-kix_rq3xt9bxxo4d-7>li:before{content:"\0025cb   "}.lst-kix_rq3xt9bxxo4d-8>li:before{content:"\0025a0   "}.lst-kix_psld3evi66f5-0>li{counter-increment:lst-ctn-kix_psld3evi66f5-0}.lst-kix_rq3xt9bxxo4d-6>li:before{content:"\0025cf   "}.lst-kix_9g9y5bz36tci-6>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-6}.lst-kix_rq3xt9bxxo4d-4>li:before{content:"\0025cb   "}ol.lst-kix_9g9y5bz36tci-8{list-style-type:none}ol.lst-kix_9g9y5bz36tci-7{list-style-type:none}ol.lst-kix_oj6uyb282fur-0.start{counter-reset:lst-ctn-kix_oj6uyb282fur-0 0}ol.lst-kix_kqerte93uwcj-7.start{counter-reset:lst-ctn-kix_kqerte93uwcj-7 0}.lst-kix_rq3xt9bxxo4d-1>li:before{content:"\0025cb   "}.lst-kix_rq3xt9bxxo4d-5>li:before{content:"\0025a0   "}ol.lst-kix_psld3evi66f5-7.start{counter-reset:lst-ctn-kix_psld3evi66f5-7 0}ol.lst-kix_9g9y5bz36tci-0{list-style-type:none}ol.lst-kix_9g9y5bz36tci-2{list-style-type:none}ol.lst-kix_9g9y5bz36tci-1{list-style-type:none}.lst-kix_rq3xt9bxxo4d-2>li:before{content:"\0025a0   "}ol.lst-kix_9g9y5bz36tci-4{list-style-type:none}ol.lst-kix_9g9y5bz36tci-3{list-style-type:none}.lst-kix_kqerte93uwcj-8>li:before{content:"" counter(lst-ctn-kix_kqerte93uwcj-8,lower-roman) ". "}.lst-kix_rq3xt9bxxo4d-3>li:before{content:"\0025cf   "}ol.lst-kix_9g9y5bz36tci-6{list-style-type:none}ol.lst-kix_9g9y5bz36tci-5{list-style-type:none}.lst-kix_ovvv5ewfi6n3-2>li:before{content:"\0025a0   "}.lst-kix_ovvv5ewfi6n3-3>li:before{content:"\0025cf   "}.lst-kix_9g9y5bz36tci-8>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-8}.lst-kix_ovvv5ewfi6n3-0>li:before{content:"\0025cf   "}.lst-kix_ovvv5ewfi6n3-8>li:before{content:"\0025a0   "}.lst-kix_psld3evi66f5-1>li:before{content:"" counter(lst-ctn-kix_psld3evi66f5-1,upper-latin) ". "}.lst-kix_ovvv5ewfi6n3-1>li:before{content:"\0025cb   "}ul.lst-kix_6rknmht6yj93-6{list-style-type:none}ul.lst-kix_6rknmht6yj93-7{list-style-type:none}.lst-kix_psld3evi66f5-2>li:before{content:"" counter(lst-ctn-kix_psld3evi66f5-2,decimal) ". "}.lst-kix_psld3evi66f5-3>li:before{content:"" counter(lst-ctn-kix_psld3evi66f5-3,lower-latin) ") "}ul.lst-kix_6rknmht6yj93-8{list-style-type:none}ol.lst-kix_oj6uyb282fur-8{list-style-type:none}ul.lst-kix_6rknmht6yj93-2{list-style-type:none}ol.lst-kix_oj6uyb282fur-7{list-style-type:none}ul.lst-kix_6rknmht6yj93-3{list-style-type:none}.lst-kix_psld3evi66f5-4>li:before{content:"(" counter(lst-ctn-kix_psld3evi66f5-4,decimal) ") "}ol.lst-kix_oj6uyb282fur-6{list-style-type:none}ul.lst-kix_6rknmht6yj93-4{list-style-type:none}.lst-kix_ovvv5ewfi6n3-7>li:before{content:"\0025cb   "}ol.lst-kix_oj6uyb282fur-5{list-style-type:none}ul.lst-kix_6rknmht6yj93-5{list-style-type:none}ol.lst-kix_oj6uyb282fur-4{list-style-type:none}.lst-kix_ovvv5ewfi6n3-6>li:before{content:"\0025cf   "}ol.lst-kix_oj6uyb282fur-3{list-style-type:none}.lst-kix_psld3evi66f5-6>li:before{content:"(" counter(lst-ctn-kix_psld3evi66f5-6,lower-roman) ") "}.lst-kix_psld3evi66f5-7>li:before{content:"(" counter(lst-ctn-kix_psld3evi66f5-7,lower-latin) ") "}ol.lst-kix_oj6uyb282fur-2{list-style-type:none}ul.lst-kix_6rknmht6yj93-0{list-style-type:none}ol.lst-kix_oj6uyb282fur-1{list-style-type:none}ul.lst-kix_6rknmht6yj93-1{list-style-type:none}ol.lst-kix_oj6uyb282fur-0{list-style-type:none}.lst-kix_ovvv5ewfi6n3-4>li:before{content:"\0025cb   "}.lst-kix_psld3evi66f5-5>li:before{content:"(" counter(lst-ctn-kix_psld3evi66f5-5,lower-latin) ") "}.lst-kix_ovvv5ewfi6n3-5>li:before{content:"\0025a0   "}ul.lst-kix_pjq3nr88nkxs-3{list-style-type:none}ul.lst-kix_pjq3nr88nkxs-4{list-style-type:none}ul.lst-kix_pjq3nr88nkxs-1{list-style-type:none}ul.lst-kix_pjq3nr88nkxs-2{list-style-type:none}ul.lst-kix_pjq3nr88nkxs-7{list-style-type:none}ul.lst-kix_pjq3nr88nkxs-8{list-style-type:none}.lst-kix_psld3evi66f5-8>li:before{content:"(" counter(lst-ctn-kix_psld3evi66f5-8,lower-roman) ") "}ul.lst-kix_pjq3nr88nkxs-5{list-style-type:none}ul.lst-kix_pjq3nr88nkxs-6{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-0{list-style-type:none}.lst-kix_kqerte93uwcj-1>li{counter-increment:lst-ctn-kix_kqerte93uwcj-1}ul.lst-kix_ovvv5ewfi6n3-1{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-2{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-3{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-4{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-5{list-style-type:none}ul.lst-kix_pjq3nr88nkxs-0{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-6{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-7{list-style-type:none}ul.lst-kix_ovvv5ewfi6n3-8{list-style-type:none}ol.lst-kix_psld3evi66f5-1.start{counter-reset:lst-ctn-kix_psld3evi66f5-1 0}ol.lst-kix_oj6uyb282fur-5.start{counter-reset:lst-ctn-kix_oj6uyb282fur-5 0}.lst-kix_oj6uyb282fur-0>li{counter-increment:lst-ctn-kix_oj6uyb282fur-0}ol.lst-kix_kqerte93uwcj-2.start{counter-reset:lst-ctn-kix_kqerte93uwcj-2 0}.lst-kix_psld3evi66f5-2>li{counter-increment:lst-ctn-kix_psld3evi66f5-2}.lst-kix_kqerte93uwcj-8>li{counter-increment:lst-ctn-kix_kqerte93uwcj-8}.lst-kix_rq3xt9bxxo4d-0>li:before{content:"\0025cf   "}ol.lst-kix_psld3evi66f5-2.start{counter-reset:lst-ctn-kix_psld3evi66f5-2 0}ol.lst-kix_kqerte93uwcj-8.start{counter-reset:lst-ctn-kix_kqerte93uwcj-8 0}ol.lst-kix_kqerte93uwcj-1.start{counter-reset:lst-ctn-kix_kqerte93uwcj-1 0}ol.lst-kix_oj6uyb282fur-6.start{counter-reset:lst-ctn-kix_oj6uyb282fur-6 0}ol.lst-kix_psld3evi66f5-8.start{counter-reset:lst-ctn-kix_psld3evi66f5-8 0}ol.lst-kix_9g9y5bz36tci-2.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-2 0}.lst-kix_3bkhzfle7x0q-0>li:before{content:"\0025cf   "}.lst-kix_9g9y5bz36tci-1>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-1}.lst-kix_kqerte93uwcj-3>li{counter-increment:lst-ctn-kix_kqerte93uwcj-3}.lst-kix_trboa99q619-8>li:before{content:"\0025a0   "}.lst-kix_3bkhzfle7x0q-4>li:before{content:"\0025cb   "}.lst-kix_3bkhzfle7x0q-2>li:before{content:"\0025a0   "}.lst-kix_3bkhzfle7x0q-6>li:before{content:"\0025cf   "}.lst-kix_9g9y5bz36tci-0>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-0}ol.lst-kix_oj6uyb282fur-7.start{counter-reset:lst-ctn-kix_oj6uyb282fur-7 0}.lst-kix_c0hzicc8kgm0-2>li:before{content:"\0025a0   "}.lst-kix_psld3evi66f5-4>li{counter-increment:lst-ctn-kix_psld3evi66f5-4}ol.lst-kix_9g9y5bz36tci-5.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-5 0}.lst-kix_oj6uyb282fur-2>li{counter-increment:lst-ctn-kix_oj6uyb282fur-2}ul.lst-kix_8giikabfykif-0{list-style-type:none}.lst-kix_c0hzicc8kgm0-0>li:before{content:"\0025cf   "}ol.lst-kix_psld3evi66f5-0.start{counter-reset:lst-ctn-kix_psld3evi66f5-0 0}ul.lst-kix_8giikabfykif-5{list-style-type:none}ol.lst-kix_kqerte93uwcj-3.start{counter-reset:lst-ctn-kix_kqerte93uwcj-3 0}ol.lst-kix_kqerte93uwcj-6.start{counter-reset:lst-ctn-kix_kqerte93uwcj-6 0}ul.lst-kix_8giikabfykif-6{list-style-type:none}ul.lst-kix_8giikabfykif-7{list-style-type:none}.lst-kix_kqerte93uwcj-4>li{counter-increment:lst-ctn-kix_kqerte93uwcj-4}ul.lst-kix_8giikabfykif-8{list-style-type:none}.lst-kix_43m80evrq7j3-6>li:before{content:"\0025cf   "}ul.lst-kix_8giikabfykif-1{list-style-type:none}ul.lst-kix_8giikabfykif-2{list-style-type:none}.lst-kix_9g9y5bz36tci-2>li{counter-increment:lst-ctn-kix_9g9y5bz36tci-2}ul.lst-kix_8giikabfykif-3{list-style-type:none}ul.lst-kix_8giikabfykif-4{list-style-type:none}.lst-kix_5fifcvmgojtk-5>li:before{content:"\0025a0   "}.lst-kix_pjq3nr88nkxs-2>li:before{content:"\0025a0   "}.lst-kix_pjq3nr88nkxs-4>li:before{content:"\0025cb   "}ol.lst-kix_oj6uyb282fur-8.start{counter-reset:lst-ctn-kix_oj6uyb282fur-8 0}.lst-kix_p2qk8baner5z-2>li:before{content:"\0025a0   "}ul.lst-kix_c0hzicc8kgm0-6{list-style-type:none}ul.lst-kix_c0hzicc8kgm0-7{list-style-type:none}.lst-kix_pjq3nr88nkxs-0>li:before{content:"\0025cf   "}ul.lst-kix_c0hzicc8kgm0-4{list-style-type:none}.lst-kix_43m80evrq7j3-4>li:before{content:"\0025cb   "}.lst-kix_pjq3nr88nkxs-8>li:before{content:"\0025a0   "}ul.lst-kix_c0hzicc8kgm0-5{list-style-type:none}.lst-kix_p2qk8baner5z-0>li:before{content:"\0025cf   "}.lst-kix_5fifcvmgojtk-7>li:before{content:"\0025cb   "}ul.lst-kix_c0hzicc8kgm0-8{list-style-type:none}.lst-kix_43m80evrq7j3-0>li:before{content:"\0025cf   "}.lst-kix_43m80evrq7j3-2>li:before{content:"\0025a0   "}ul.lst-kix_c0hzicc8kgm0-2{list-style-type:none}.lst-kix_c0hzicc8kgm0-4>li:before{content:"\0025cb   "}ul.lst-kix_c0hzicc8kgm0-3{list-style-type:none}ul.lst-kix_c0hzicc8kgm0-0{list-style-type:none}.lst-kix_8giikabfykif-2>li:before{content:"\0025a0   "}ul.lst-kix_c0hzicc8kgm0-1{list-style-type:none}.lst-kix_psld3evi66f5-3>li{counter-increment:lst-ctn-kix_psld3evi66f5-3}.lst-kix_c0hzicc8kgm0-6>li:before{content:"\0025cf   "}.lst-kix_pjq3nr88nkxs-6>li:before{content:"\0025cf   "}ol.lst-kix_9g9y5bz36tci-4.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-4 0}.lst-kix_8giikabfykif-0>li:before{content:"\0025cf   "}.lst-kix_trboa99q619-0>li:before{content:"\0025cf   "}.lst-kix_kqerte93uwcj-6>li:before{content:"" counter(lst-ctn-kix_kqerte93uwcj-6,decimal) ". "}ol.lst-kix_kqerte93uwcj-5.start{counter-reset:lst-ctn-kix_kqerte93uwcj-5 0}ol.lst-kix_9g9y5bz36tci-3.start{counter-reset:lst-ctn-kix_9g9y5bz36tci-3 0}.lst-kix_c0hzicc8kgm0-8>li:before{content:"\0025a0   "}.lst-kix_oj6uyb282fur-1>li{counter-increment:lst-ctn-kix_oj6uyb282fur-1}.lst-kix_8giikabfykif-6>li:before{content:"\0025cf   "}.lst-kix_trboa99q619-4>li:before{content:"\0025cb   "}.lst-kix_3bkhzfle7x0q-8>li:before{content:"\0025a0   "}.lst-kix_trboa99q619-6>li:before{content:"\0025cf   "}.lst-kix_kqerte93uwcj-4>li:before{content:"(" counter(lst-ctn-kix_kqerte93uwcj-4,lower-latin) ") "}.lst-kix_oj6uyb282fur-7>li{counter-increment:lst-ctn-kix_oj6uyb282fur-7}.lst-kix_8giikabfykif-4>li:before{content:"\0025cb   "}.lst-kix_kqerte93uwcj-2>li:before{content:"" counter(lst-ctn-kix_kqerte93uwcj-2,lower-roman) ") "}.lst-kix_trboa99q619-2>li:before{content:"\0025a0   "}.lst-kix_kqerte93uwcj-0>li:before{content:"" counter(lst-ctn-kix_kqerte93uwcj-0,decimal) ") "}.lst-kix_8giikabfykif-8>li:before{content:"\0025a0   "}ol{margin:0;padding:0}table td,table th{padding:0}.c4{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:87.8pt;border-top-color:#000000;border-bottom-style:solid}.c18{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:154.5pt;border-top-color:#000000;border-bottom-style:solid}.c7{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:189.8pt;border-top-color:#000000;border-bottom-style:solid}.c12{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#ffffff;border-bottom-style:solid}.c1{margin-left:72pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c8{margin-left:108pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center;height:11pt}.c22{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c13{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c16{margin-left:22.5pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c15{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c6{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c17{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c24{border-spacing:0;border-collapse:collapse;margin-right:auto}.c10{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c21{margin-left:36pt;padding-left:0pt}.c0{padding:0;margin:0}.c20{color:inherit;text-decoration:inherit}.c23{margin-left:36pt}.c28{height:24pt}.c14{font-size:10pt}.c19{margin-left:72pt}.c25{}.c27{margin-left:108pt}.c11{height:0pt}.c26{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c10"><p class="c15"><span class="c22">CS445 Final Project Report (Project6 + CS497)</span></p><p class="c15"><span class="c22">2.5D Live Holographic Teleconference</span></p><p class="c15"><span class="c22">(Real-time projection with occlusion)</span></p><p class="c2"><span class="c3"></span></p><p class="c15"><span class="c3">Team: Ching-Hua Yu (cyu17), Hung Woei Neoh (hneoh2), Vasista Vovveti (vovveti2)</span></p><p class="c5"><span class="c3"></span></p><p class="c13"><span class="c3">Abstract:</span></p><p class="c13"><span class="c3">Our core plan is to cut a person from a video and paste the person into another video with occlusion treatment. Both videos are obtained from real time video streams. The pasting comes with additional processing to scale the person&rsquo;s size relative to the scene.</span></p><p class="c13"><span class="c14">Demo: </span><span class="c6 c14"><a class="c20" href="https://www.google.com/url?q=https://drive.google.com/file/d/1n4Dv4Xl115nDUSUJaDqGNQ_tj1tIgWSE/view?usp%3Dsharing&amp;sa=D&amp;ust=1599838448228000&amp;usg=AOvVaw3zmVJ59J_pLbs-ItHVPEmN">https://drive.google.com/file/d/1n4Dv4Xl115nDUSUJaDqGNQ_tj1tIgWSE/view?usp=sharing</a></span></p><p class="c5"><span class="c3"></span></p><ol class="c0 lst-kix_psld3evi66f5-0 start" start="1"><li class="c9"><span class="c3">Introduction</span></li></ol><ul class="c0 lst-kix_43m80evrq7j3-0 start"><li class="c9"><span class="c3">The tools used in this are a webcam and a Kinect </span></li><li class="c9"><span class="c3">Design framework - The challenges of the project involves three parts</span></li></ul><ul class="c0 lst-kix_43m80evrq7j3-1 start"><li class="c1"><span class="c3">Foreground Extraction</span></li></ul><ul class="c0 lst-kix_43m80evrq7j3-2 start"><li class="c8"><span class="c3">Segmentation based approaches (Ching-Hua)</span></li><li class="c8"><span class="c3">Background subtraction (Vasista and Hung Woei)</span></li></ul><ul class="c0 lst-kix_43m80evrq7j3-1"><li class="c1"><span class="c3">Background depth map masking</span></li></ul><ul class="c0 lst-kix_43m80evrq7j3-2 start"><li class="c8"><span class="c3">Using Kinect (Vasista)</span></li><li class="c8"><span class="c3">Using traditional cameras where we proposed an improved approach (Ching-Hua)</span></li></ul><ul class="c0 lst-kix_43m80evrq7j3-1"><li class="c1"><span class="c3">Projection scaling and positioning (Hung Woei)</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 492.75px; height: 340.50px;"><img alt="" src="images/image6.png" style="width: 492.75px; height: 340.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><ol class="c0 lst-kix_psld3evi66f5-0" start="2"><li class="c9"><span class="c3">Foreground extraction to obtain the foreground character</span></li></ol><ul class="c0 lst-kix_pjq3nr88nkxs-1 start"><li class="c1"><span class="c3">The task is to extract interesting foreground objects that we can hologram into another scene.</span></li><li class="c1"><span class="c3">There are two methods we compare for this task: 1) Background subtraction with a static background (store as an initial frame to subtract) 2) Segmentation based approach to extract objects</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><ul class="c0 lst-kix_pjq3nr88nkxs-0 start"><li class="c9"><span class="c3">Segmentation based approach:</span></li></ul><ul class="c0 lst-kix_pjq3nr88nkxs-1 start"><li class="c1"><span class="c3">We used Mask R-CNN (He et al. ICCV&rsquo;17) for segmentation with a public model mask_rcnn_coco.</span></li><li class="c1"><span class="c3">Example: The input video is 1280x720 24fps that contains a person. The source is clipped from (Will Stephen, How to sound smart in your TEDx Talk, TEDxNewYork) The background is a static image 1280x720 with tables:</span></li><li class="c1"><span>The static image </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=https://drive.google.com/file/d/1ObhhAMsk3FapcpdoxIGD52nO_uMAK2Hb/view?usp%3Dsharing&amp;sa=D&amp;ust=1599838448231000&amp;usg=AOvVaw0oA2bjpOg6JGuP8bz9JsV-">https://drive.google.com/file/d/1ObhhAMsk3FapcpdoxIGD52nO_uMAK2Hb/view?usp=sharing</a></span><span>&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 479.50px; height: 269.72px;"><img alt="" src="images/image13.png" style="width: 479.50px; height: 269.72px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c1"><span>The input video </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=https://drive.google.com/file/d/1dwCtqKUyOYlKg4GMYnGm84lGCcFYBo4b/view?usp%3Dsharing&amp;sa=D&amp;ust=1599838448231000&amp;usg=AOvVaw1ZbxVZD3cvT7r-zluEI-S6">https://drive.google.com/file/d/1dwCtqKUyOYlKg4GMYnGm84lGCcFYBo4b/view?usp=sharing</a></span></li><li class="c1"><span>The mask of the object (person) </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=https://drive.google.com/file/d/1POBoNNiMufxdvXpsRvinRRqxBog3_G89/view?usp%3Dsharing&amp;sa=D&amp;ust=1599838448232000&amp;usg=AOvVaw0j6zHV36cS82xzBlHSD7Uo">https://drive.google.com/file/d/1POBoNNiMufxdvXpsRvinRRqxBog3_G89/view?usp=sharing</a></span></li><li class="c1"><span>The output video </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=https://drive.google.com/file/d/1qKlpS3ggUuJyhk1C95NDOX4Vn74fBvab/view?usp%3Dsharing&amp;sa=D&amp;ust=1599838448232000&amp;usg=AOvVaw1D7YZtOrbiRHC8LLNkdl_b">https://drive.google.com/file/d/1qKlpS3ggUuJyhk1C95NDOX4Vn74fBvab/view?usp=sharing</a></span></li><li class="c1"><span class="c3">Average processing time of per frame:</span></li></ul><ul class="c0 lst-kix_pjq3nr88nkxs-2 start"><li class="c8"><span class="c3">8.74 sec on Intel Core-i7 CPU</span></li><li class="c8"><span class="c3">0.99 sec on Nvidia GTX-1050 2GB</span></li><li class="c8"><span class="c3">0.00017 sec on Google colab with 1 GPU</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><ul class="c0 lst-kix_pjq3nr88nkxs-0"><li class="c9"><span class="c3">Background subtraction </span></li></ul><ul class="c0 lst-kix_pjq3nr88nkxs-1 start"><li class="c1"><span>In midterm report, we have an initial test </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=https://drive.google.com/file/d/1DnA0fasf8guKHHNjEhjgvdgX88cigbvH/view?usp%3Dsharing&amp;sa=D&amp;ust=1599838448233000&amp;usg=AOvVaw1BM3fgLnIXdtVefZWJ78Bl">https://drive.google.com/file/d/1DnA0fasf8guKHHNjEhjgvdgX88cigbvH/view?usp=sharing</a></span><span>&nbsp;(by manually made function). Here we use StereoBM_create from opencv instead. Note that the quality is improved since the openCV function uses some more involved steps.</span></li><li class="c1"><span class="c3">We implemented background subtraction to extract the foreground character from a scene to be pasted into a different background</span></li><li class="c1"><span class="c3">This is done using the background subtraction library functions in OpenCV</span></li><li class="c1"><span>The background subtraction algorithm used is the Gaussian mixture-based MOG algorithm from </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=http://personal.ee.surrey.ac.uk/Personal/R.Bowden/publications/avbs01/avbs01.pdf&amp;sa=D&amp;ust=1599838448234000&amp;usg=AOvVaw3S0SkeaftzPg5d4hrKJzu6">this paper</a></span></li><li class="c1"><span class="c3">The extracted foreground mask suffers from random white spots within the mask. To remedy this, we dilate the mask multiple times to cover up the white spots, and erode it to revert it back to its original shape</span></li><li class="c1"><span class="c3">Issues: If one black pixel remains inside the mask after dilation, the erosion will magnify those pixels, resulting in diamond shaped black holes within the mask</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><a id="t.a12b639471ea931192f0439e2a125c54850582e8"></a><a id="t.0"></a><table class="c24 c25"><tbody><tr class="c11"><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 224.00px;"><img alt="" src="images/image2.png" style="width: 298.00px; height: 224.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">The foreground mask obtained from Background Subtraction</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 224.00px;"><img alt="" src="images/image14.png" style="width: 298.00px; height: 224.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">The foreground object extracted and pasted</span></p><p class="c15"><span class="c3">onto a different background</span></p></td></tr></tbody></table><p class="c5"><span class="c3"></span></p><p class="c2"><span class="c3"></span></p><p class="c2"><span class="c3"></span></p><p class="c5 c27"><span class="c3"></span></p><ul class="c0 lst-kix_pjq3nr88nkxs-0"><li class="c9"><span class="c3">Comparisons of the two methods</span></li></ul><p class="c5 c23"><span class="c3"></span></p><a id="t.fa28df8f074115e50fcf587e714d781fae101cf5"></a><a id="t.1"></a><table class="c24 c23"><tbody><tr class="c11"><td class="c4" colspan="1" rowspan="1"><p class="c17 c26"><span class="c3"></span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c17"><span class="c3">Traditional BGS</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c17"><span class="c3">Segmentation-based</span></p></td></tr><tr class="c11"><td class="c4" colspan="1" rowspan="1"><p class="c17"><span class="c3">Advantage</span></p></td><td class="c18" colspan="1" rowspan="1"><ul class="c0 lst-kix_8giikabfykif-0 start"><li class="c16"><span class="c3">Fast</span></li><li class="c16"><span class="c3">Easy to implement with OpenCV library</span></li></ul></td><td class="c7" colspan="1" rowspan="1"><ul class="c0 lst-kix_8giikabfykif-0"><li class="c17 c21"><span class="c3">Identifies individual objects</span></li><li class="c17 c21"><span class="c3">Works for dynamic background (since objects are separated)</span></li><li class="c17 c21"><span class="c3">Solid foreground masks</span></li><li class="c17 c21"><span class="c3">Real-time with today&rsquo;s GPU </span></li></ul></td></tr><tr class="c11"><td class="c4" colspan="1" rowspan="1"><p class="c17"><span class="c3">Disadvantage</span></p></td><td class="c18" colspan="1" rowspan="1"><ul class="c0 lst-kix_ovvv5ewfi6n3-0 start"><li class="c16"><span class="c3">Mask is not solid, requires post processing</span></li><li class="c16"><span class="c3">Works on static background only</span></li><li class="c16"><span class="c3">Cannot separate multiple objects in foreground</span></li></ul></td><td class="c7" colspan="1" rowspan="1"><ul class="c0 lst-kix_ovvv5ewfi6n3-0"><li class="c17 c21"><span class="c3">Consume more computation power</span></li></ul></td></tr></tbody></table><p class="c5 c23"><span class="c3"></span></p><p class="c5 c23"><span class="c3"></span></p><p class="c13 c23"><span class="c3">&nbsp;</span></p><ol class="c0 lst-kix_psld3evi66f5-0" start="3"><li class="c9"><span class="c3">Obtaining a depth map from a background scene using Kinect</span></li></ol><ul class="c0 lst-kix_pjq3nr88nkxs-0"><li class="c9"><span class="c3">Using Kinect</span></li></ul><ul class="c0 lst-kix_pjq3nr88nkxs-1 start"><li class="c1"><span class="c3">The kinect provides relatively stable colorful frames and depth frames.</span></li><li class="c1"><span class="c3">The colorful frames and the depth frames are from two cameras and have a short distance. Hence we have to warp the frames and align them first (using some techniques from Project 5).</span></li><li class="c1"><span class="c3">Example of depth map from Kinect:</span></li></ul><p class="c13 c19"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 242.50px; height: 207.86px;"><img alt="" src="images/image11.png" style="width: 242.50px; height: 207.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 246.25px; height: 210.50px;"><img alt="" src="images/image4.png" style="width: 246.25px; height: 210.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c0 lst-kix_pjq3nr88nkxs-1"><li class="c1"><span class="c3">Temporal Locality</span></li></ul><ul class="c0 lst-kix_pjq3nr88nkxs-2 start"><li class="c8"><span class="c3">In this depth image, black denotes unknown depth. When unknown depth is detected, that location is filled with the last known value. </span></li><li class="c8"><span class="c3">This greatly reduces recurring noise in the image.</span></li></ul><p class="c13 c19"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 377.63px; height: 281.19px;"><img alt="" src="images/image3.png" style="width: 377.63px; height: 281.19px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c0 lst-kix_pjq3nr88nkxs-1"><li class="c1"><span class="c3">&nbsp;</span></li></ul><p class="c5"><span class="c3"></span></p><ul class="c0 lst-kix_pjq3nr88nkxs-0"><li class="c9"><span class="c3">Using Traditional Camera</span></li></ul><ul class="c0 lst-kix_pjq3nr88nkxs-1 start"><li class="c1"><span class="c3">The approach would need two (left/right) cameras of the same kind; otherwise, there will be some more alignment jobs to be done.</span></li><li class="c1"><span class="c3">With one camera, we can still work around by shifting the camera a bit, but then it can only serve for a static background creation (with a depth map).</span></li><li class="c1"><span class="c3">The main problem of the traditional camera is that there are too many noise, so no matter how numDisparities and blockSize tuned, it&rsquo;s not possible to get a clean mask (compared to the ones from Kinect)</span></li><li class="c1"><span class="c3">We solve this problem by using a (real-time) segmentation. The segmentation function provides masks of foreground objects without depth information. Then we use the depth map to decide the depth of the objects.</span></li><li class="c1"><span class="c3">As it relies the performance of segmentation, scenes like classrooms (with clear objects that have been well trained to detect) are easier.</span></li><li class="c1"><span class="c3">Example:</span></li></ul><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 140.00px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 140.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ol class="c0 lst-kix_kqerte93uwcj-0 start" start="1"><li class="c9"><span class="c3">As we can see above, the depth map is hard to &nbsp;clean</span></li></ol><p class="c5"><span class="c3"></span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 302.29px; height: 177.50px;"><img alt="" src="images/image17.png" style="width: 302.29px; height: 177.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ol class="c0 lst-kix_kqerte93uwcj-0" start="2"><li class="c9"><span class="c3">We estimate the &ldquo;dense&rdquo; of each object mask one by one</span></li></ol><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 304.56px; height: 178.50px;"><img alt="" src="images/image10.png" style="width: 304.56px; height: 178.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ol class="c0 lst-kix_kqerte93uwcj-0" start="3"><li class="c9"><span class="c3">With the threshold condition, we can get object mask of a certain depth even cleaner than those from Kinect. </span></li></ol><ul class="c0 lst-kix_pjq3nr88nkxs-0"><li class="c9"><span class="c3">Comparison of two methods</span></li></ul><p class="c5 c23"><span class="c3"></span></p><a id="t.c087eaef7c257a4309628e0b56c7f41f820172c2"></a><a id="t.2"></a><table class="c23 c24"><tbody><tr class="c28"><td class="c4" colspan="1" rowspan="1"><p class="c17"><span class="c3">Depth-map masking</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c17"><span class="c3">Kinect</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c17"><span class="c3">Traditional Cameras + Segmentation improvement</span></p></td></tr><tr class="c11"><td class="c4" colspan="1" rowspan="1"><p class="c17"><span class="c3">Advantage</span></p></td><td class="c18" colspan="1" rowspan="1"><ul class="c0 lst-kix_8giikabfykif-0"><li class="c16"><span class="c3">Fast, easy to be real-time</span></li><li class="c16"><span class="c3">Providing color frames and depth frames measured from distinct cameras stably</span></li></ul></td><td class="c7" colspan="1" rowspan="1"><ul class="c0 lst-kix_8giikabfykif-0"><li class="c17 c21"><span class="c3">No special device required</span></li><li class="c17 c21"><span class="c3">Good quality</span></li></ul></td></tr><tr class="c11"><td class="c4" colspan="1" rowspan="1"><p class="c17"><span class="c3">Disadvantage</span></p></td><td class="c18" colspan="1" rowspan="1"><ul class="c0 lst-kix_ovvv5ewfi6n3-0"><li class="c16"><span class="c3">Need Kinect (ver 2.0 has a better quality than ver 1.0)</span></li></ul></td><td class="c7" colspan="1" rowspan="1"><ul class="c0 lst-kix_ovvv5ewfi6n3-0"><li class="c17 c21"><span class="c3">Consume more computational power (but real-time with GPU)</span></li></ul></td></tr></tbody></table><p class="c5 c23"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><p class="c13"><span class="c3">IV. Projection scaling and positioning</span></p><ul class="c0 lst-kix_3bkhzfle7x0q-0 start"><li class="c9"><span class="c3">Adjusting the foreground character&rsquo;s size and position in the composite video through interactive user interface</span></li></ul><ul class="c0 lst-kix_3bkhzfle7x0q-1 start"><li class="c1"><span class="c3">We created an interactive interface in Jupyter notebook which allows the user to identify the vanishing line of the image, the positions of reference objects and objects to be pasted, as well as their heights.</span></li></ul><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 301.50px; height: 235.83px;"><img alt="" src="images/image7.jpg" style="width: 301.50px; height: 235.83px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">Jupyter notebook comes with convenient UI interfaces that takes user inputs and applies these inputs to a function every time the parameters change</span></p><p class="c2"><span class="c3"></span></p><ul class="c0 lst-kix_3bkhzfle7x0q-1"><li class="c1"><span class="c3">Then, using the computation methods from lecture, we calculated how many pixels the object to be pasted would occupy</span></li><li class="c1"><span class="c3">We then resize the object and its mask, and performed the necessary translation to add the object at the desired location with the desired height</span></li></ul><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 431.50px; height: 242.72px;"><img alt="" src="images/image16.png" style="width: 431.50px; height: 242.72px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">The person from the TEDTalk sample video, resized and repositioned accordingly</span></p><p class="c2"><span class="c3"></span></p><ul class="c0 lst-kix_3bkhzfle7x0q-1"><li class="c1"><span class="c3">The reason this didn&rsquo;t make the cut is because this does not give us the depth mapping needed for occlusion. Thus, this code was shelved, and we simply allow users to resize the character manually</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><p class="c13"><span class="c3">V. Results:</span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 353.33px;"><img alt="" src="images/image18.png" style="width: 624.00px; height: 353.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c13"><span class="c3">We created a GUI that allows users to select the size and location of the source object in the destination frame. x and y denote horizontal and vertical translation, respectively. z denotes depth translation (into the page =&gt; out of the page). As you can see in these images, the depth location can be dynamically changed in real-time by the user.</span></p><p class="c13"><span class="c14">Demo: </span><span class="c6 c14"><a class="c20" href="https://www.google.com/url?q=https://drive.google.com/file/d/1n4Dv4Xl115nDUSUJaDqGNQ_tj1tIgWSE/view?usp%3Dsharing&amp;sa=D&amp;ust=1599838448249000&amp;usg=AOvVaw3Iq6fawh_Ohf5NUV-DSEd3">https://drive.google.com/file/d/1n4Dv4Xl115nDUSUJaDqGNQ_tj1tIgWSE/view?usp=sharing</a></span></p><p class="c5"><span class="c3"></span></p><p class="c13"><span class="c3">Techniques and ideas that we attempted, but more refinement are needed</span></p><ul class="c0 lst-kix_trboa99q619-0 start"><li class="c9"><span class="c3">Automated detection of vanishing lines</span></li></ul><ul class="c0 lst-kix_trboa99q619-1 start"><li class="c1"><span class="c3">To automatically detect vanishing lines, the idea was to extract projection lines on a given image/scene and compute the intersection points between those lines. Then, by looking for dense clusters of intersection points, we can approximate vanishing points and obtain the vanishing line of a scene.</span></li><li class="c1"><span>We tried to obtain lines in a given scene through edge detection algorithms. By using </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Canny_edge_detector&amp;sa=D&amp;ust=1599838448250000&amp;usg=AOvVaw3F7pllne7oeBM_EjNv-gBS">Canny Edge Detection</a></span><span>&nbsp;and </span><span class="c6"><a class="c20" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Hough_transform&amp;sa=D&amp;ust=1599838448250000&amp;usg=AOvVaw24xhyPNfuLH6tq4ZpMLeam">Hough transform</a></span><span class="c3">, we were able to extract the lines of a particular scene, as displayed below</span></li></ul><p class="c5"><span class="c3"></span></p><a id="t.506a1d4404584fa98804bdc1a91df8b9b10d0879"></a><a id="t.3"></a><table class="c24 c25"><tbody><tr class="c11"><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 168.00px;"><img alt="" src="images/image13.png" style="width: 298.00px; height: 168.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">Original scene</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 168.00px;"><img alt="" src="images/image15.png" style="width: 298.00px; height: 168.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">The edges detected by the Canny Edge algorithm, using parameters 60 and 300</span></p></td></tr><tr class="c11"><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 168.00px;"><img alt="" src="images/image1.png" style="width: 298.00px; height: 168.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">The lines detected by Hough transform, drawn onto the image</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 168.00px;"><img alt="" src="images/image8.png" style="width: 298.00px; height: 168.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">The extracted lines, drawn onto a blank canvas</span></p></td></tr></tbody></table><p class="c5"><span class="c3"></span></p><ul class="c0 lst-kix_trboa99q619-1"><li class="c1"><span class="c3">However, the lines obtained from the Hough transform consisted of many individual short segments, as observed from plotting the obtained lines using matplotlib. Many of these lines are almost parallel to each other, and therefore can intersect anywhere ranging from within the image, to tens or hundreds of thousands of pixels outside the image region. This resulted in a lot of noise and inaccuracy in determining clusters of intersection points</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><a id="t.5e6d89bcf651f548b176c44f7801cd90f0b3fd6b"></a><a id="t.4"></a><table class="c24 c25"><tbody><tr class="c11"><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 318.50px; height: 212.69px;"><img alt="" src="images/image9.png" style="width: 318.50px; height: 212.69px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">The numerous amount of colors indicates a lot of separate line segments</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 168.00px;"><img alt="" src="images/image12.png" style="width: 298.00px; height: 168.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c3">A plot of all the intersection points of the line segments that are within the image region. As observed, there are intersection points throughout the entire image</span></p></td></tr></tbody></table><p class="c5"><span class="c3"></span></p><p class="c2"><span class="c3"></span></p><ul class="c0 lst-kix_trboa99q619-1"><li class="c1"><span class="c3">The Canny Edge detection and Hough transform also had parameters that need to be adjusted for different scenes. There is no single set of values that fit all possible scenes, which makes it hard to automate</span></li></ul><ul class="c0 lst-kix_trboa99q619-0"><li class="c9"><span class="c3">Detection of forward/backward movement of foreground characters</span></li></ul><ul class="c0 lst-kix_trboa99q619-1 start"><li class="c1"><span class="c3">We wanted to be able to detect movements of foreground characters, and display those movements accurately in the given image</span></li><li class="c1"><span class="c3">However, that would mean that we would need to compute a depth map of the moving person, or estimate the forward/backward movements through the growth/shrinking of the person from frame to frame. Then, we would need to shift the position where we paste the person accordingly in the background image. This is a non-trivial amount of work, and we do not have any clear ideas on how to go about this</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><p class="c5"><span class="c3"></span></p><p class="c13"><span class="c3">V. Possible extensions</span></p><ul class="c0 lst-kix_rq3xt9bxxo4d-0 start"><li class="c9"><span class="c3">Better depth-map masks</span></li></ul><ul class="c0 lst-kix_rq3xt9bxxo4d-1 start"><li class="c1"><span class="c3">In order to achieve 2.5D (i.e., with occlusion), we need the background with depth information.</span></li><li class="c1"><span class="c3">The depth map generated by either Kinect or two traditional cameras doesn&rsquo;t have individual objects separated. We are developing an approach to combining traditional depth map with segmentation for higher accuracy. </span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-0 start"><li class="c9"><span class="c3">Extracting foreground using both traditional BGS and segmentation</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-1 start"><li class="c1"><span class="c3">Segmentation based approach is more stable and suitable for more general purpose (since objects are identified separately).</span></li><li class="c1"><span class="c3">traditional BGS is fast</span></li><li class="c1"><span class="c3">An alternative way is to run segmentation once a while and and use BGS information to adjust the existing mask.</span></li><li class="c1"><span class="c3">These two are part of motivated by [2].</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-0"><li class="c9"><span class="c3">Blending the pasted character</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-1 start"><li class="c1"><span class="c3">Some sort of color processing, such as blending the character to fit in better into the image, could be implemented to make the character look like it was part of the image.</span></li><li class="c1"><span class="c3">Adjusting the lighting on the foreground character would be useful for integrating two different scenes with different lighting conditions. Right now, we assume that both scenes have the same lighting conditions</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-0"><li class="c9"><span class="c3">Adding in shadows</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-1 start"><li class="c1"><span class="c3">We could also compute shadows for human characters around their feet</span></li><li class="c1"><span class="c3">If we could get MOG2 background subtraction to work with dilation/erosion, we can get the shadows from the original image without additional computation</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-0"><li class="c9"><span class="c3">Finding a way to obtain better vanishing point prediction</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-1 start"><li class="c1"><span class="c3">One possible method is to sample lines that are close together, and join these lines to form a longer line. Having longer lines will enable us to better predict the vanishing points, as it reduces noise</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-0"><li class="c9"><span class="c3">Detecting forward/backward movement from the character</span></li></ul><ul class="c0 lst-kix_6rknmht6yj93-1 start"><li class="c1"><span class="c3">When such movement is detected, we can then adjust the feet&rsquo;s position as well as the depth map of the individual</span></li><li class="c1"><span class="c3">Non-trivial, will require a method to estimate distance from camera</span></li></ul><p class="c5"><span class="c3"></span></p><p class="c13"><span class="c3">[1] Kaiming He, Georgia Gkioxari, Piotr Dollar, Ross Girshick. Mask R-CNN. IEEE ICCV 2017</span></p><p class="c13"><span class="c3">[2] Dongdong Zeng, Xiang Chen, Ming Zhu, Michael Goesele and Arjan Kuijper. Background Subtraction with Real-time Semantic Segmentation. IEEE Access 2019.</span></p><p class="c5"><span class="c3"></span></p></body></html>